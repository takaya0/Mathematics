\documentclass[11pt, a4paper, english, dvipdfmx]{jsarticle}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[psamsfonts]{amssymb}
\usepackage{color}
\usepackage{ascmac}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{fancybox}
\usepackage{enumerate}
\usepackage{verbatim}
\usepackage{subfigure}
\usepackage{proof}
\usepackage{listings}
\usepackage{otf}

\theoremstyle{definition}

%
%%%%%%%%%%%%%%%%%%%%%%
%ここにないパッケージを入れる人は，必ずここに記載すること.
%
%%%%%%%%%%%%%%%%%%%%%%
%ここからはコード表です.
%

%英語で定義や定理を書きたい場合こっちのコードを使うこと.

\newtheorem{Axiom+}{Axiom}[section]
\newtheorem{Definition+}[Axiom+]{Definition}
\newtheorem{Theorem+}[Axiom+]{Theorem}
\newtheorem{Proposition+}[Axiom+]{Proposition}
\newtheorem{Lemma+}[Axiom+]{Lemma}
\newtheorem{Example+}[Axiom+]{Example}
\newtheorem{Corollary+}[Axiom+]{Corollary}
\newtheorem{Claim+}[Axiom+]{Claim}
\newtheorem{Property+}[Axiom+]{Property}
\newtheorem{Attention+}[Axiom+]{Attention}
\newtheorem{Question+}[Axiom+]{Question}
\newtheorem{Problem+}[Axiom+]{Problem}
\newtheorem{Consideration+}[Axiom+]{Consideration}
\newtheorem{Alert+}{Alert}

\def\hoge<#1>{\langle #1 \rangle}
%commmand

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\Y}{\mathcal{Y}}
\newcommand{\Hil}{\mathcal{H}}
\renewcommand{\L}{\mathcal{L}}
\newcommand{\W}{{\cal W}}
\newcommand{\cS}{{\cal S}}
\newcommand{\Wpm}{W^{\pm}}
\newcommand{\Wp}{W^{+}}
\newcommand{\Wm}{W^{-}}
\newcommand{\p}{\partial}
\newcommand{\Dx}{D_{x}}
\newcommand{\Dxi}{D_{\xi}}
\newcommand{\lan}{\langle}
\newcommand{\ran}{\rangle}
\newcommand{\pal}{\parallel}
\newcommand{\dip}{\displaystyle}
\newcommand{\e}{\varepsilon}
\newcommand{\dl}{\delta}
\newcommand{\pphi}{\varphi}
\newcommand{\ti}{\tilde}
\title{Extending some linear methods to nonlinear methods by positive definite kernel and RKHS}
\author{yataka}
\date{}
\begin{document}
\maketitle
\setcounter{section}{-1}
\section{Motivation and Notation}
\subsection{Motivation}
Thre are a lot of Machine Learning methods which approximate linear data.
However, most of data in this World are non-linear. Thus, we show you a method, called kernel method, that
embed data of input space into high dimentional vector space with inner.
\subsection{Notation}
\noindent
$\X$: input space\\
$\Y$: output space\\
$\L$: Loss function\\
$\K$: field\\
$V$: vector space\\
$(V, \|\cdot\|)$: normed space\\
$(V, \hoge<\cdot, \cdot>)$ : inner space\\
$\Hil$: hypothesis space or Hilbert space\\
$\Hil_{k}$: RKHS with positive definate kernel $k$\\
\section{Functional Analysis}
\begin{Definition+}(vector space)\\
    Let $\K$, $V$ be a field and a set with two operations, addition and scalar multiplication.
    If $V$ statisfies
    \begin{enumerate}
        \item $V$ becomes commutative group by addition,
        \item $\forall\alpha\in\K, \forall u, v\in V, \alpha(u + v) = \alpha u + \alpha v$,
        \item $\forall \alpha, \beta\in\K, \forall v\in V, (\alpha + \beta)v = \alpha v + \beta v$,
        \item $\forall \alpha, \beta\in\K, \forall v\in V, \alpha(\beta v) = (\alpha\beta)v$ and 
        \item $\exists 1_{\K}\in\K~\text{ s.t. }\forall v\in V, 1_{\K}v = v$.
    \end{enumerate}
    Then, $V$ is called $\mathbf{vector~space}$ over $\K$.
\end{Definition+}
We consider only real verctor space or complex vector space in this article. Thus, 
$\K = \R$ or $\K = \C$.
\begin{Definition+}(normed vector space)\\
    Let $V$, $\|\cdot\|$ be a vector space over $\K$ and a map from $V$ to $\K$.
    $\|\cdot\|$ is called $\mathbf{norm}$ on $\K$ when $\|\|$ statisfies 
    \begin{enumerate}
        \item $\forall v\in V, \|v\| \geq 0$,
        \item $\forall v\in V, \|v\| = 0 \iff v = 0$,
        \item $\forall \alpha\in\K, \forall v\in V, \|\alpha v\| = |\alpha|\|v\|$ and 
        \item $\forall v, w\in V, \|v + w\|\leq \|v\| + \|w\|$.
    \end{enumerate}
    A pair $(V, \|\|)$ is called $\mathbf{normed~vector~space}$ or $\mathbf{normed~space}$
\end{Definition+}
\begin{Proposition+}
    Suppose that $(V, \|\|)$ is normed space.
    Then, norm space is metric space by a distance $d:V\times V\to\K$ generated  by norm,
    \begin{align*}
        d(x, y) = \|x - y\|.
    \end{align*}
\end{Proposition+}

\begin{Definition+}(complete)\\
    Let $(X, d)$ be metric space.
    $(X, d)$ is called $\mathbf{complete}$ when every cauchy sequence in $X$ converges a element in $X$.
\end{Definition+}

\begin{Definition+}(compact)\\
    Let $(X, \mathscr{O})$ be topological space. 
    X is called compact if every open covering of $X$ has finite open covering. i.e.
    \begin{align*}
        \forall \{O_{\lambda}\}_{\lambda\in\Lambda}\subset\mathscr{O},  X = \bigcup_{\lambda\in\Lambda}O_{\lambda}\Longrightarrow\exists\lambda_{1}, \lambda_{n}, \cdots, \lambda_{n}\text{ s.t. }X = \bigcup_{i = 1}^{n}O_{\lambda_{i}}
    \end{align*}
\end{Definition+}

\begin{Definition+}(Banach space)\\
    Let $(V, \|\|)$ be normed space. 
    $(V, \|\|)$ is called $\mathbf{Banach~space}$ when $V$ is complete by a distance generated by norm.
\end{Definition+}
Banach space is very important space in mathematics. 
Therefore, I show you some examples of Banach space.
\begin{Example+}($C[X]$)\\
    Let $X$ be compact space. Suppose that $C[X]$ is a collection of all continuous functions on $X$.
    We define a norm on $X$ below:
    \begin{align*}
        \|x\|_{\infty} = \max\{|x(t)|~|t\in X\}.
    \end{align*}
    Then, $(C[X],\|\|_{\infty})$ becomes Banach space.
\end{Example+}
\begin{Example+}($\mathcal{L}^p(a, b)$, $p\geq 1$)\\
    Let $(a, b)$ be interval. Suppose that $((a, b), \mathcal{B}(a, b), L)$ is 
    measure space where $\mathcal{B}(a, b)$ is Borel space and $L$ is Lebesugue measure. we define $L^{p}(a, b)$ as
    \begin{align*}
        L^p(a, b) := \left\{x:(a, b)\to\K~|\int_{a}^{b}|x(t)|^{p}dt < \infty\right\}
    \end{align*} 
    and a norm as
    \begin{align*}
        \|x\|_{p} = \left(\int_{a}^{b}|x(t)|^{p}dt\right)^{\frac{1}{p}}.
    \end{align*}
    We consider a equivarence relation $\sim$ on $L^{p}(a, b)$. $x\sim y$ is defined 
    $x(t) = y(t)~a.s.t\in (a, b)$. Then, a collection of all equivarence classes on $L^{p}(a, b)$ is donated 
    $\mathcal{L}^{p}(a, b)$ and becomes a vector space under addition and scalar multiplication defined by
    \begin{align*}
        (x + y)(y) = x(t) + y(t)\hspace{20pt}(\alpha x)(t) = \alpha x(t).
    \end{align*}

    A pair $(\mathcal{L}^{p}, \|\|_{p})$ is Banach space and called $\mathbf{L^{p}~space}$.
\end{Example+}
\begin{Definition+}(inner space)\\
    Let $V$ be vector space over $\K$. Suppose that $\hoge<\cdot, \cdot>$ is a map from $V\times V$ to $\K$
    which statisfies
    \begin{enumerate}
        \item $\forall v\in V, \hoge<v, v>\geq 0$,
        \item $\forall v\in V, \hoge<v, v> = 0\iff v = 0$,
        \item $\forall v, w\in V, \hoge<v, w> = \overline{\hoge<w, v>}$,
        \item $\forall u, v, w\in V, \hoge<u + v, w> = \hoge<u, w> + \hoge<v, w>$ and
        \item $\forall v, w\in V, \forall\alpha\in\K, \hoge<\alpha v, w> = \alpha\hoge<v, w>$.
    \end{enumerate}
    Then, a pair $(V, \hoge<\cdot, \cdot>)$ is called $\mathbf{inner~space}$ and $\hoge<\cdot, \cdot>$ is called $\mathbf{inner}$ on $V$.
\end{Definition+}

\begin{Proposition+}
    Let $(V, \hoge<\cdot, \cdot>)$ be inner space over $\K$.
    we difine a map $\|\cdot\|$ from $V$ to $\K$ as
    \begin{align*}
        \|x\| = \sqrt{\hoge<x, x>}.
    \end{align*}
    Then, $\|\cdot\|$ is a norm on $V$ and is called norm generated by inner. 
\end{Proposition+}
\begin{Definition+}(Hilbert space)\\
    Let $(V, \hoge<\cdot, \cdot>)$ be inner space.
    $V$ is called $\mathbf{Hilbert~space}$ if $V$ is banach space by a norm generated by inner.
\end{Definition+}

\section{Positive definate kernel}

\begin{Definition+}(positive definate kernel)\\
    Let $\X$, $k$ be a set and a map from $\X\times\X$ to $\K$.
    $k$ is called $\mathbf{positive~definate~kernel}$ on $\K$ if 
    $k$ has two conditions below:
    \begin{enumerate}
        \item $\forall x, y\in\X, k(x, y) = k(y, x)$ and
        \item $\forall n\in\N, \forall x_{1}, \cdots, x_{n}\in\X, \forall c_{1}, \cdots, c_{n}\in\R$,
              \begin{align*}
                  \sum_{i = 1}^{n}\sum_{j = 1}^{n}c_{i}c_{j}k(x_{i}, x_{j})\geq 0.
              \end{align*}
    \end{enumerate}
    second condition is called $\mathbf{definiteness}$. definiteness under symmetrically means that a matrix
    \begin{align*}
        \left(\begin{array}{ccc}
            {k\left(x_{1}, x_{1}\right)} & {\dots} & {k\left(x_{1}, x_{n}\right)} \\
            {\vdots} & {\ddots} & {\vdots} \\
            {k\left(x_{n}, x_{1}\right)} & {\cdots} & {k\left(x_{n}, x_{n}\right)}
        \end{array}\right)
    \end{align*}
    is positive-semidefinite. This symmetric matrix is called $\mathbf{gram~matrix}$.
\end{Definition+}
\begin{Proposition+}
    Let $k:\X\times\X\to\K$ be positive definate kernel. Then, 
    \begin{enumerate}
        \item $\forall x\in\X, k(x, x)\geq 0$,
        \item $\forall x, y\in\X, |k(x, y)|^2\geq k(x, x)k(y, y)$ and
        \item every subset $\Y$, $k_{|\Y\times\Y}$ is positive difine kernel too.
    \end{enumerate}
    \begin{proof}
        1.)~From definateness of $k$, $1\times 1\times k(x, x)\geq 0$ for every $x$ in $\X$. Hence, 
        $k(x, x)\geq 0$.\\
        2.) I can't prove....\\
        3.)~It is clear.
    \end{proof}
\end{Proposition+}

\begin{Proposition+}
    Let $\X$, $\{k_{n}\}_{n\in\N}$ be a set and a sequence of positive definate kernal on $\K$.
    Then, $\alpha k_{1} + \beta k_{2}(\alpha, \beta \geq 0)$, $k_{1}k_{2}$, $\dip \lim_{n\to\infty}k_{n}$ are also positive definate kernels.
    However, we asusme that 
    \begin{enumerate}
        \item $\forall x, y\in\X, k_{1}k_{2}(x, y) = k_{1}(x, y)k_{2}(x, y)$ and
        \item $\{k_{n}\}_{n\in\N}$ converges a map $k:\X\times\X\to\K$ .
    \end{enumerate}
    \begin{proof}
        just a moment please....
    \end{proof}
\end{Proposition+}

\begin{Proposition+}
    Let $\X$ be a set.
    \begin{enumerate}
        \item A non negative constant map $k:\X\times\X\to\{c\}~(c\in\R_{\geq 0})$ is positive definate kernel.
        \item Let $k:\X\times\X\to\C$ be positive definate kernal. Then, a map $k^{'}:\X\times\X\to\C$, defined by 
        \begin{align*}
            k^{'}(x, y) = f(x)k(x, y)\overline{f(y)},
        \end{align*} 
        is positive definate kernel for every function $f:\X\to\C$.
    \end{enumerate}
\end{Proposition+}

\begin{Proposition+}(kernel tric)\\
    Let $\X$, $(V, \hoge<\cdot, \cdot>)$ be a set and inner space. a map $k:\X\times\X\to\K$, defined by 
    \begin{align*}
        k(x, y) = \hoge<\Phi(x), \Phi(y)>,
    \end{align*}
    is positive definate kernal for every function $\Phi:\X\to V$.
\end{Proposition+}
\section{Reproducing Kernel Hilbert Space}
\begin{Definition+}(reproducing kernel Hilbert space)\\
    Let $\X$, $\Hil$ be a set and Hilbert space from some functions on $\X$.\\
    $\Hil$ is called $\mathbf{Reproducing~Kernel~Hilbert~Space}$ or $\mathbf{RKHS}$ simply when
    \begin{align*}
        \forall x\in\X, \exists k_{x}\in\Hil\text{ s.t. }\forall f\in\Hil, \hoge<f, k_{x}> = f(x).
    \end{align*} 
    a map $k:\X\times\X\to\K$, defined by $k(y, x) = k_{x}(y)$, is called $\mathbf{reproducing~kernel}$ of $\Hil$. 
\end{Definition+}
\end{document}
